{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[20/10000], loss: 8.450413\n",
      "Epoch[40/10000], loss: 6.028246\n",
      "Epoch[60/10000], loss: 4.316390\n",
      "Epoch[80/10000], loss: 3.106536\n",
      "Epoch[100/10000], loss: 2.251469\n",
      "Epoch[120/10000], loss: 1.647148\n",
      "Epoch[140/10000], loss: 1.220041\n",
      "Epoch[160/10000], loss: 0.918180\n",
      "Epoch[180/10000], loss: 0.704834\n",
      "Epoch[200/10000], loss: 0.554047\n",
      "Epoch[220/10000], loss: 0.447472\n",
      "Epoch[240/10000], loss: 0.372145\n",
      "Epoch[260/10000], loss: 0.318900\n",
      "Epoch[280/10000], loss: 0.281264\n",
      "Epoch[300/10000], loss: 0.254659\n",
      "Epoch[320/10000], loss: 0.235849\n",
      "Epoch[340/10000], loss: 0.222548\n",
      "Epoch[360/10000], loss: 0.213142\n",
      "Epoch[380/10000], loss: 0.206487\n",
      "Epoch[400/10000], loss: 0.201778\n",
      "Epoch[420/10000], loss: 0.198443\n",
      "Epoch[440/10000], loss: 0.196079\n",
      "Epoch[460/10000], loss: 0.194403\n",
      "Epoch[480/10000], loss: 0.193211\n",
      "Epoch[500/10000], loss: 0.192363\n",
      "Epoch[520/10000], loss: 0.191756\n",
      "Epoch[540/10000], loss: 0.191322\n",
      "Epoch[560/10000], loss: 0.191008\n",
      "Epoch[580/10000], loss: 0.190780\n",
      "Epoch[600/10000], loss: 0.190612\n",
      "Epoch[620/10000], loss: 0.190487\n",
      "Epoch[640/10000], loss: 0.190392\n",
      "Epoch[660/10000], loss: 0.190319\n",
      "Epoch[680/10000], loss: 0.190261\n",
      "Epoch[700/10000], loss: 0.190213\n",
      "Epoch[720/10000], loss: 0.190173\n",
      "Epoch[740/10000], loss: 0.190139\n",
      "Epoch[760/10000], loss: 0.190108\n",
      "Epoch[780/10000], loss: 0.190080\n",
      "Epoch[800/10000], loss: 0.190054\n",
      "Epoch[820/10000], loss: 0.190029\n",
      "Epoch[840/10000], loss: 0.190005\n",
      "Epoch[860/10000], loss: 0.189981\n",
      "Epoch[880/10000], loss: 0.189959\n",
      "Epoch[900/10000], loss: 0.189936\n",
      "Epoch[920/10000], loss: 0.189914\n",
      "Epoch[940/10000], loss: 0.189892\n",
      "Epoch[960/10000], loss: 0.189870\n",
      "Epoch[980/10000], loss: 0.189849\n",
      "Epoch[1000/10000], loss: 0.189827\n",
      "Epoch[1020/10000], loss: 0.189806\n",
      "Epoch[1040/10000], loss: 0.189784\n",
      "Epoch[1060/10000], loss: 0.189763\n",
      "Epoch[1080/10000], loss: 0.189741\n",
      "Epoch[1100/10000], loss: 0.189720\n",
      "Epoch[1120/10000], loss: 0.189698\n",
      "Epoch[1140/10000], loss: 0.189677\n",
      "Epoch[1160/10000], loss: 0.189656\n",
      "Epoch[1180/10000], loss: 0.189634\n",
      "Epoch[1200/10000], loss: 0.189613\n",
      "Epoch[1220/10000], loss: 0.189592\n",
      "Epoch[1240/10000], loss: 0.189570\n",
      "Epoch[1260/10000], loss: 0.189549\n",
      "Epoch[1280/10000], loss: 0.189528\n",
      "Epoch[1300/10000], loss: 0.189507\n",
      "Epoch[1320/10000], loss: 0.189486\n",
      "Epoch[1340/10000], loss: 0.189465\n",
      "Epoch[1360/10000], loss: 0.189444\n",
      "Epoch[1380/10000], loss: 0.189422\n",
      "Epoch[1400/10000], loss: 0.189401\n",
      "Epoch[1420/10000], loss: 0.189380\n",
      "Epoch[1440/10000], loss: 0.189359\n",
      "Epoch[1460/10000], loss: 0.189338\n",
      "Epoch[1480/10000], loss: 0.189317\n",
      "Epoch[1500/10000], loss: 0.189296\n",
      "Epoch[1520/10000], loss: 0.189276\n",
      "Epoch[1540/10000], loss: 0.189255\n",
      "Epoch[1560/10000], loss: 0.189234\n",
      "Epoch[1580/10000], loss: 0.189213\n",
      "Epoch[1600/10000], loss: 0.189192\n",
      "Epoch[1620/10000], loss: 0.189171\n",
      "Epoch[1640/10000], loss: 0.189150\n",
      "Epoch[1660/10000], loss: 0.189130\n",
      "Epoch[1680/10000], loss: 0.189109\n",
      "Epoch[1700/10000], loss: 0.189088\n",
      "Epoch[1720/10000], loss: 0.189067\n",
      "Epoch[1740/10000], loss: 0.189047\n",
      "Epoch[1760/10000], loss: 0.189026\n",
      "Epoch[1780/10000], loss: 0.189005\n",
      "Epoch[1800/10000], loss: 0.188985\n",
      "Epoch[1820/10000], loss: 0.188964\n",
      "Epoch[1840/10000], loss: 0.188944\n",
      "Epoch[1860/10000], loss: 0.188923\n",
      "Epoch[1880/10000], loss: 0.188902\n",
      "Epoch[1900/10000], loss: 0.188882\n",
      "Epoch[1920/10000], loss: 0.188861\n",
      "Epoch[1940/10000], loss: 0.188841\n",
      "Epoch[1960/10000], loss: 0.188821\n",
      "Epoch[1980/10000], loss: 0.188800\n",
      "Epoch[2000/10000], loss: 0.188780\n",
      "Epoch[2020/10000], loss: 0.188759\n",
      "Epoch[2040/10000], loss: 0.188739\n",
      "Epoch[2060/10000], loss: 0.188719\n",
      "Epoch[2080/10000], loss: 0.188698\n",
      "Epoch[2100/10000], loss: 0.188678\n",
      "Epoch[2120/10000], loss: 0.188658\n",
      "Epoch[2140/10000], loss: 0.188637\n",
      "Epoch[2160/10000], loss: 0.188617\n",
      "Epoch[2180/10000], loss: 0.188597\n",
      "Epoch[2200/10000], loss: 0.188577\n",
      "Epoch[2220/10000], loss: 0.188557\n",
      "Epoch[2240/10000], loss: 0.188536\n",
      "Epoch[2260/10000], loss: 0.188516\n",
      "Epoch[2280/10000], loss: 0.188496\n",
      "Epoch[2300/10000], loss: 0.188476\n",
      "Epoch[2320/10000], loss: 0.188456\n",
      "Epoch[2340/10000], loss: 0.188436\n",
      "Epoch[2360/10000], loss: 0.188416\n",
      "Epoch[2380/10000], loss: 0.188396\n",
      "Epoch[2400/10000], loss: 0.188376\n",
      "Epoch[2420/10000], loss: 0.188356\n",
      "Epoch[2440/10000], loss: 0.188336\n",
      "Epoch[2460/10000], loss: 0.188316\n",
      "Epoch[2480/10000], loss: 0.188296\n",
      "Epoch[2500/10000], loss: 0.188276\n",
      "Epoch[2520/10000], loss: 0.188256\n",
      "Epoch[2540/10000], loss: 0.188236\n",
      "Epoch[2560/10000], loss: 0.188216\n",
      "Epoch[2580/10000], loss: 0.188197\n",
      "Epoch[2600/10000], loss: 0.188177\n",
      "Epoch[2620/10000], loss: 0.188157\n",
      "Epoch[2640/10000], loss: 0.188137\n",
      "Epoch[2660/10000], loss: 0.188118\n",
      "Epoch[2680/10000], loss: 0.188098\n",
      "Epoch[2700/10000], loss: 0.188078\n",
      "Epoch[2720/10000], loss: 0.188059\n",
      "Epoch[2740/10000], loss: 0.188039\n",
      "Epoch[2760/10000], loss: 0.188019\n",
      "Epoch[2780/10000], loss: 0.188000\n",
      "Epoch[2800/10000], loss: 0.187980\n",
      "Epoch[2820/10000], loss: 0.187960\n",
      "Epoch[2840/10000], loss: 0.187941\n",
      "Epoch[2860/10000], loss: 0.187921\n",
      "Epoch[2880/10000], loss: 0.187902\n",
      "Epoch[2900/10000], loss: 0.187882\n",
      "Epoch[2920/10000], loss: 0.187863\n",
      "Epoch[2940/10000], loss: 0.187843\n",
      "Epoch[2960/10000], loss: 0.187824\n",
      "Epoch[2980/10000], loss: 0.187805\n",
      "Epoch[3000/10000], loss: 0.187785\n",
      "Epoch[3020/10000], loss: 0.187766\n",
      "Epoch[3040/10000], loss: 0.187746\n",
      "Epoch[3060/10000], loss: 0.187727\n",
      "Epoch[3080/10000], loss: 0.187708\n",
      "Epoch[3100/10000], loss: 0.187689\n",
      "Epoch[3120/10000], loss: 0.187669\n",
      "Epoch[3140/10000], loss: 0.187650\n",
      "Epoch[3160/10000], loss: 0.187631\n",
      "Epoch[3180/10000], loss: 0.187612\n",
      "Epoch[3200/10000], loss: 0.187592\n",
      "Epoch[3220/10000], loss: 0.187573\n",
      "Epoch[3240/10000], loss: 0.187554\n",
      "Epoch[3260/10000], loss: 0.187535\n",
      "Epoch[3280/10000], loss: 0.187516\n",
      "Epoch[3300/10000], loss: 0.187497\n",
      "Epoch[3320/10000], loss: 0.187478\n",
      "Epoch[3340/10000], loss: 0.187459\n",
      "Epoch[3360/10000], loss: 0.187440\n",
      "Epoch[3380/10000], loss: 0.187421\n",
      "Epoch[3400/10000], loss: 0.187401\n",
      "Epoch[3420/10000], loss: 0.187382\n",
      "Epoch[3440/10000], loss: 0.187364\n",
      "Epoch[3460/10000], loss: 0.187345\n",
      "Epoch[3480/10000], loss: 0.187326\n",
      "Epoch[3500/10000], loss: 0.187307\n",
      "Epoch[3520/10000], loss: 0.187288\n",
      "Epoch[3540/10000], loss: 0.187269\n",
      "Epoch[3560/10000], loss: 0.187250\n",
      "Epoch[3580/10000], loss: 0.187231\n",
      "Epoch[3600/10000], loss: 0.187213\n",
      "Epoch[3620/10000], loss: 0.187194\n",
      "Epoch[3640/10000], loss: 0.187175\n",
      "Epoch[3660/10000], loss: 0.187156\n",
      "Epoch[3680/10000], loss: 0.187138\n",
      "Epoch[3700/10000], loss: 0.187119\n",
      "Epoch[3720/10000], loss: 0.187100\n",
      "Epoch[3740/10000], loss: 0.187082\n",
      "Epoch[3760/10000], loss: 0.187063\n",
      "Epoch[3780/10000], loss: 0.187044\n",
      "Epoch[3800/10000], loss: 0.187026\n",
      "Epoch[3820/10000], loss: 0.187007\n",
      "Epoch[3840/10000], loss: 0.186988\n",
      "Epoch[3860/10000], loss: 0.186970\n",
      "Epoch[3880/10000], loss: 0.186951\n",
      "Epoch[3900/10000], loss: 0.186933\n",
      "Epoch[3920/10000], loss: 0.186914\n",
      "Epoch[3940/10000], loss: 0.186896\n",
      "Epoch[3960/10000], loss: 0.186877\n",
      "Epoch[3980/10000], loss: 0.186859\n",
      "Epoch[4000/10000], loss: 0.186841\n",
      "Epoch[4020/10000], loss: 0.186822\n",
      "Epoch[4040/10000], loss: 0.186804\n",
      "Epoch[4060/10000], loss: 0.186785\n",
      "Epoch[4080/10000], loss: 0.186767\n",
      "Epoch[4100/10000], loss: 0.186749\n",
      "Epoch[4120/10000], loss: 0.186730\n",
      "Epoch[4140/10000], loss: 0.186712\n",
      "Epoch[4160/10000], loss: 0.186694\n",
      "Epoch[4180/10000], loss: 0.186676\n",
      "Epoch[4200/10000], loss: 0.186657\n",
      "Epoch[4220/10000], loss: 0.186639\n",
      "Epoch[4240/10000], loss: 0.186621\n",
      "Epoch[4260/10000], loss: 0.186603\n",
      "Epoch[4280/10000], loss: 0.186585\n",
      "Epoch[4300/10000], loss: 0.186566\n",
      "Epoch[4320/10000], loss: 0.186548\n",
      "Epoch[4340/10000], loss: 0.186530\n",
      "Epoch[4360/10000], loss: 0.186512\n",
      "Epoch[4380/10000], loss: 0.186494\n",
      "Epoch[4400/10000], loss: 0.186476\n",
      "Epoch[4420/10000], loss: 0.186458\n",
      "Epoch[4440/10000], loss: 0.186440\n",
      "Epoch[4460/10000], loss: 0.186422\n",
      "Epoch[4480/10000], loss: 0.186404\n",
      "Epoch[4500/10000], loss: 0.186386\n",
      "Epoch[4520/10000], loss: 0.186368\n",
      "Epoch[4540/10000], loss: 0.186350\n",
      "Epoch[4560/10000], loss: 0.186332\n",
      "Epoch[4580/10000], loss: 0.186314\n",
      "Epoch[4600/10000], loss: 0.186297\n",
      "Epoch[4620/10000], loss: 0.186279\n",
      "Epoch[4640/10000], loss: 0.186261\n",
      "Epoch[4660/10000], loss: 0.186243\n",
      "Epoch[4680/10000], loss: 0.186225\n",
      "Epoch[4700/10000], loss: 0.186208\n",
      "Epoch[4720/10000], loss: 0.186190\n",
      "Epoch[4740/10000], loss: 0.186172\n",
      "Epoch[4760/10000], loss: 0.186154\n",
      "Epoch[4780/10000], loss: 0.186137\n",
      "Epoch[4800/10000], loss: 0.186119\n",
      "Epoch[4820/10000], loss: 0.186101\n",
      "Epoch[4840/10000], loss: 0.186084\n",
      "Epoch[4860/10000], loss: 0.186066\n",
      "Epoch[4880/10000], loss: 0.186048\n",
      "Epoch[4900/10000], loss: 0.186031\n",
      "Epoch[4920/10000], loss: 0.186013\n",
      "Epoch[4940/10000], loss: 0.185996\n",
      "Epoch[4960/10000], loss: 0.185978\n",
      "Epoch[4980/10000], loss: 0.185961\n",
      "Epoch[5000/10000], loss: 0.185943\n",
      "Epoch[5020/10000], loss: 0.185926\n",
      "Epoch[5040/10000], loss: 0.185908\n",
      "Epoch[5060/10000], loss: 0.185891\n",
      "Epoch[5080/10000], loss: 0.185873\n",
      "Epoch[5100/10000], loss: 0.185856\n",
      "Epoch[5120/10000], loss: 0.185839\n",
      "Epoch[5140/10000], loss: 0.185821\n",
      "Epoch[5160/10000], loss: 0.185804\n",
      "Epoch[5180/10000], loss: 0.185786\n",
      "Epoch[5200/10000], loss: 0.185769\n",
      "Epoch[5220/10000], loss: 0.185752\n",
      "Epoch[5240/10000], loss: 0.185734\n",
      "Epoch[5260/10000], loss: 0.185717\n",
      "Epoch[5280/10000], loss: 0.185700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5300/10000], loss: 0.185683\n",
      "Epoch[5320/10000], loss: 0.185666\n",
      "Epoch[5340/10000], loss: 0.185648\n",
      "Epoch[5360/10000], loss: 0.185631\n",
      "Epoch[5380/10000], loss: 0.185614\n",
      "Epoch[5400/10000], loss: 0.185597\n",
      "Epoch[5420/10000], loss: 0.185580\n",
      "Epoch[5440/10000], loss: 0.185563\n",
      "Epoch[5460/10000], loss: 0.185546\n",
      "Epoch[5480/10000], loss: 0.185529\n",
      "Epoch[5500/10000], loss: 0.185511\n",
      "Epoch[5520/10000], loss: 0.185494\n",
      "Epoch[5540/10000], loss: 0.185477\n",
      "Epoch[5560/10000], loss: 0.185460\n",
      "Epoch[5580/10000], loss: 0.185443\n",
      "Epoch[5600/10000], loss: 0.185426\n",
      "Epoch[5620/10000], loss: 0.185409\n",
      "Epoch[5640/10000], loss: 0.185393\n",
      "Epoch[5660/10000], loss: 0.185376\n",
      "Epoch[5680/10000], loss: 0.185359\n",
      "Epoch[5700/10000], loss: 0.185342\n",
      "Epoch[5720/10000], loss: 0.185325\n",
      "Epoch[5740/10000], loss: 0.185308\n",
      "Epoch[5760/10000], loss: 0.185291\n",
      "Epoch[5780/10000], loss: 0.185274\n",
      "Epoch[5800/10000], loss: 0.185258\n",
      "Epoch[5820/10000], loss: 0.185241\n",
      "Epoch[5840/10000], loss: 0.185224\n",
      "Epoch[5860/10000], loss: 0.185207\n",
      "Epoch[5880/10000], loss: 0.185191\n",
      "Epoch[5900/10000], loss: 0.185174\n",
      "Epoch[5920/10000], loss: 0.185157\n",
      "Epoch[5940/10000], loss: 0.185141\n",
      "Epoch[5960/10000], loss: 0.185124\n",
      "Epoch[5980/10000], loss: 0.185107\n",
      "Epoch[6000/10000], loss: 0.185091\n",
      "Epoch[6020/10000], loss: 0.185074\n",
      "Epoch[6040/10000], loss: 0.185057\n",
      "Epoch[6060/10000], loss: 0.185041\n",
      "Epoch[6080/10000], loss: 0.185024\n",
      "Epoch[6100/10000], loss: 0.185008\n",
      "Epoch[6120/10000], loss: 0.184991\n",
      "Epoch[6140/10000], loss: 0.184975\n",
      "Epoch[6160/10000], loss: 0.184958\n",
      "Epoch[6180/10000], loss: 0.184942\n",
      "Epoch[6200/10000], loss: 0.184925\n",
      "Epoch[6220/10000], loss: 0.184909\n",
      "Epoch[6240/10000], loss: 0.184892\n",
      "Epoch[6260/10000], loss: 0.184876\n",
      "Epoch[6280/10000], loss: 0.184860\n",
      "Epoch[6300/10000], loss: 0.184843\n",
      "Epoch[6320/10000], loss: 0.184827\n",
      "Epoch[6340/10000], loss: 0.184811\n",
      "Epoch[6360/10000], loss: 0.184794\n",
      "Epoch[6380/10000], loss: 0.184778\n",
      "Epoch[6400/10000], loss: 0.184762\n",
      "Epoch[6420/10000], loss: 0.184745\n",
      "Epoch[6440/10000], loss: 0.184729\n",
      "Epoch[6460/10000], loss: 0.184713\n",
      "Epoch[6480/10000], loss: 0.184697\n",
      "Epoch[6500/10000], loss: 0.184681\n",
      "Epoch[6520/10000], loss: 0.184664\n",
      "Epoch[6540/10000], loss: 0.184648\n",
      "Epoch[6560/10000], loss: 0.184632\n",
      "Epoch[6580/10000], loss: 0.184616\n",
      "Epoch[6600/10000], loss: 0.184600\n",
      "Epoch[6620/10000], loss: 0.184584\n",
      "Epoch[6640/10000], loss: 0.184568\n",
      "Epoch[6660/10000], loss: 0.184552\n",
      "Epoch[6680/10000], loss: 0.184535\n",
      "Epoch[6700/10000], loss: 0.184519\n",
      "Epoch[6720/10000], loss: 0.184503\n",
      "Epoch[6740/10000], loss: 0.184487\n",
      "Epoch[6760/10000], loss: 0.184471\n",
      "Epoch[6780/10000], loss: 0.184455\n",
      "Epoch[6800/10000], loss: 0.184439\n",
      "Epoch[6820/10000], loss: 0.184424\n",
      "Epoch[6840/10000], loss: 0.184408\n",
      "Epoch[6860/10000], loss: 0.184392\n",
      "Epoch[6880/10000], loss: 0.184376\n",
      "Epoch[6900/10000], loss: 0.184360\n",
      "Epoch[6920/10000], loss: 0.184344\n",
      "Epoch[6940/10000], loss: 0.184328\n",
      "Epoch[6960/10000], loss: 0.184312\n",
      "Epoch[6980/10000], loss: 0.184297\n",
      "Epoch[7000/10000], loss: 0.184281\n",
      "Epoch[7020/10000], loss: 0.184265\n",
      "Epoch[7040/10000], loss: 0.184249\n",
      "Epoch[7060/10000], loss: 0.184234\n",
      "Epoch[7080/10000], loss: 0.184218\n",
      "Epoch[7100/10000], loss: 0.184202\n",
      "Epoch[7120/10000], loss: 0.184186\n",
      "Epoch[7140/10000], loss: 0.184171\n",
      "Epoch[7160/10000], loss: 0.184155\n",
      "Epoch[7180/10000], loss: 0.184139\n",
      "Epoch[7200/10000], loss: 0.184124\n",
      "Epoch[7220/10000], loss: 0.184108\n",
      "Epoch[7240/10000], loss: 0.184093\n",
      "Epoch[7260/10000], loss: 0.184077\n",
      "Epoch[7280/10000], loss: 0.184062\n",
      "Epoch[7300/10000], loss: 0.184046\n",
      "Epoch[7320/10000], loss: 0.184030\n",
      "Epoch[7340/10000], loss: 0.184015\n",
      "Epoch[7360/10000], loss: 0.183999\n",
      "Epoch[7380/10000], loss: 0.183984\n",
      "Epoch[7400/10000], loss: 0.183968\n",
      "Epoch[7420/10000], loss: 0.183953\n",
      "Epoch[7440/10000], loss: 0.183938\n",
      "Epoch[7460/10000], loss: 0.183922\n",
      "Epoch[7480/10000], loss: 0.183907\n",
      "Epoch[7500/10000], loss: 0.183891\n",
      "Epoch[7520/10000], loss: 0.183876\n",
      "Epoch[7540/10000], loss: 0.183861\n",
      "Epoch[7560/10000], loss: 0.183845\n",
      "Epoch[7580/10000], loss: 0.183830\n",
      "Epoch[7600/10000], loss: 0.183815\n",
      "Epoch[7620/10000], loss: 0.183799\n",
      "Epoch[7640/10000], loss: 0.183784\n",
      "Epoch[7660/10000], loss: 0.183769\n",
      "Epoch[7680/10000], loss: 0.183754\n",
      "Epoch[7700/10000], loss: 0.183738\n",
      "Epoch[7720/10000], loss: 0.183723\n",
      "Epoch[7740/10000], loss: 0.183708\n",
      "Epoch[7760/10000], loss: 0.183693\n",
      "Epoch[7780/10000], loss: 0.183677\n",
      "Epoch[7800/10000], loss: 0.183662\n",
      "Epoch[7820/10000], loss: 0.183647\n",
      "Epoch[7840/10000], loss: 0.183632\n",
      "Epoch[7860/10000], loss: 0.183617\n",
      "Epoch[7880/10000], loss: 0.183602\n",
      "Epoch[7900/10000], loss: 0.183587\n",
      "Epoch[7920/10000], loss: 0.183572\n",
      "Epoch[7940/10000], loss: 0.183557\n",
      "Epoch[7960/10000], loss: 0.183542\n",
      "Epoch[7980/10000], loss: 0.183527\n",
      "Epoch[8000/10000], loss: 0.183512\n",
      "Epoch[8020/10000], loss: 0.183497\n",
      "Epoch[8040/10000], loss: 0.183482\n",
      "Epoch[8060/10000], loss: 0.183467\n",
      "Epoch[8080/10000], loss: 0.183452\n",
      "Epoch[8100/10000], loss: 0.183437\n",
      "Epoch[8120/10000], loss: 0.183422\n",
      "Epoch[8140/10000], loss: 0.183407\n",
      "Epoch[8160/10000], loss: 0.183392\n",
      "Epoch[8180/10000], loss: 0.183377\n",
      "Epoch[8200/10000], loss: 0.183362\n",
      "Epoch[8220/10000], loss: 0.183348\n",
      "Epoch[8240/10000], loss: 0.183333\n",
      "Epoch[8260/10000], loss: 0.183318\n",
      "Epoch[8280/10000], loss: 0.183303\n",
      "Epoch[8300/10000], loss: 0.183288\n",
      "Epoch[8320/10000], loss: 0.183274\n",
      "Epoch[8340/10000], loss: 0.183259\n",
      "Epoch[8360/10000], loss: 0.183244\n",
      "Epoch[8380/10000], loss: 0.183229\n",
      "Epoch[8400/10000], loss: 0.183215\n",
      "Epoch[8420/10000], loss: 0.183200\n",
      "Epoch[8440/10000], loss: 0.183185\n",
      "Epoch[8460/10000], loss: 0.183171\n",
      "Epoch[8480/10000], loss: 0.183156\n",
      "Epoch[8500/10000], loss: 0.183142\n",
      "Epoch[8520/10000], loss: 0.183127\n",
      "Epoch[8540/10000], loss: 0.183112\n",
      "Epoch[8560/10000], loss: 0.183098\n",
      "Epoch[8580/10000], loss: 0.183083\n",
      "Epoch[8600/10000], loss: 0.183069\n",
      "Epoch[8620/10000], loss: 0.183054\n",
      "Epoch[8640/10000], loss: 0.183040\n",
      "Epoch[8660/10000], loss: 0.183025\n",
      "Epoch[8680/10000], loss: 0.183011\n",
      "Epoch[8700/10000], loss: 0.182996\n",
      "Epoch[8720/10000], loss: 0.182982\n",
      "Epoch[8740/10000], loss: 0.182967\n",
      "Epoch[8760/10000], loss: 0.182953\n",
      "Epoch[8780/10000], loss: 0.182938\n",
      "Epoch[8800/10000], loss: 0.182924\n",
      "Epoch[8820/10000], loss: 0.182910\n",
      "Epoch[8840/10000], loss: 0.182895\n",
      "Epoch[8860/10000], loss: 0.182881\n",
      "Epoch[8880/10000], loss: 0.182867\n",
      "Epoch[8900/10000], loss: 0.182852\n",
      "Epoch[8920/10000], loss: 0.182838\n",
      "Epoch[8940/10000], loss: 0.182824\n",
      "Epoch[8960/10000], loss: 0.182809\n",
      "Epoch[8980/10000], loss: 0.182795\n",
      "Epoch[9000/10000], loss: 0.182781\n",
      "Epoch[9020/10000], loss: 0.182767\n",
      "Epoch[9040/10000], loss: 0.182752\n",
      "Epoch[9060/10000], loss: 0.182738\n",
      "Epoch[9080/10000], loss: 0.182724\n",
      "Epoch[9100/10000], loss: 0.182710\n",
      "Epoch[9120/10000], loss: 0.182696\n",
      "Epoch[9140/10000], loss: 0.182682\n",
      "Epoch[9160/10000], loss: 0.182667\n",
      "Epoch[9180/10000], loss: 0.182653\n",
      "Epoch[9200/10000], loss: 0.182639\n",
      "Epoch[9220/10000], loss: 0.182625\n",
      "Epoch[9240/10000], loss: 0.182611\n",
      "Epoch[9260/10000], loss: 0.182597\n",
      "Epoch[9280/10000], loss: 0.182583\n",
      "Epoch[9300/10000], loss: 0.182569\n",
      "Epoch[9320/10000], loss: 0.182555\n",
      "Epoch[9340/10000], loss: 0.182541\n",
      "Epoch[9360/10000], loss: 0.182527\n",
      "Epoch[9380/10000], loss: 0.182513\n",
      "Epoch[9400/10000], loss: 0.182499\n",
      "Epoch[9420/10000], loss: 0.182485\n",
      "Epoch[9440/10000], loss: 0.182471\n",
      "Epoch[9460/10000], loss: 0.182457\n",
      "Epoch[9480/10000], loss: 0.182443\n",
      "Epoch[9500/10000], loss: 0.182429\n",
      "Epoch[9520/10000], loss: 0.182415\n",
      "Epoch[9540/10000], loss: 0.182402\n",
      "Epoch[9560/10000], loss: 0.182388\n",
      "Epoch[9580/10000], loss: 0.182374\n",
      "Epoch[9600/10000], loss: 0.182360\n",
      "Epoch[9620/10000], loss: 0.182346\n",
      "Epoch[9640/10000], loss: 0.182333\n",
      "Epoch[9660/10000], loss: 0.182319\n",
      "Epoch[9680/10000], loss: 0.182305\n",
      "Epoch[9700/10000], loss: 0.182291\n",
      "Epoch[9720/10000], loss: 0.182278\n",
      "Epoch[9740/10000], loss: 0.182264\n",
      "Epoch[9760/10000], loss: 0.182250\n",
      "Epoch[9780/10000], loss: 0.182236\n",
      "Epoch[9800/10000], loss: 0.182223\n",
      "Epoch[9820/10000], loss: 0.182209\n",
      "Epoch[9840/10000], loss: 0.182195\n",
      "Epoch[9860/10000], loss: 0.182182\n",
      "Epoch[9880/10000], loss: 0.182168\n",
      "Epoch[9900/10000], loss: 0.182155\n",
      "Epoch[9920/10000], loss: 0.182141\n",
      "Epoch[9940/10000], loss: 0.182127\n",
      "Epoch[9960/10000], loss: 0.182114\n",
      "Epoch[9980/10000], loss: 0.182100\n",
      "Epoch[10000/10000], loss: 0.182087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "__author__ = 'SherlockLiao'\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168],\n",
    "                    [9.779], [6.182], [7.59], [2.167], [7.042],\n",
    "                    [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
    "\n",
    "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573],\n",
    "                    [3.366], [2.596], [2.53], [1.221], [2.827],\n",
    "                    [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)\n",
    "\n",
    "\n",
    "x_train = torch.from_numpy(x_train)\n",
    "\n",
    "y_train = torch.from_numpy(y_train)\n",
    "\n",
    "\n",
    "# Linear Regression Model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)  # input and output is 1 dimension\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "# 定义loss和优化函数\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 开始训练\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = Variable(x_train)\n",
    "    target = Variable(y_train)\n",
    "\n",
    "    # forward\n",
    "    out = model(inputs)\n",
    "    loss = criterion(out, target)\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print('Epoch[{}/{}], loss: {:.6f}'\n",
    "              .format(epoch+1, num_epochs, loss.data[0]))\n",
    "\n",
    "model.eval()\n",
    "predict = model(Variable(x_train))\n",
    "predict = predict.data.numpy()\n",
    "plt.plot(x_train.numpy(), y_train.numpy(), 'ro', label='Original data')\n",
    "plt.plot(x_train.numpy(), predict, label='Fitting Line')\n",
    "# 显示图例\n",
    "plt.legend() \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
